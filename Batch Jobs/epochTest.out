             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
           8935512      h100 Epoch Te  hoan163  R       0:06      1 h100-04

group_by_length batching


Loading tokenizer and model

[2025-04-04 01:13:12,599] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /people/hoan163/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
LengthGroupedSampler with Smart Batching: False
[1/3] g++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -I/people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/deepspeed/ops/csrc/adam -isystem /people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/torch/include -isystem /people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/torch/include/TH -isystem /people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/torch/include/THC -isystem /share/apps/cuda/12.3/include -isystem /people/hoan163/.conda/envs/BatchTest/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DBF16_AVAILABLE -c /people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o 
[2/3] /share/apps/cuda/12.3/bin/nvcc --generate-dependencies-with-compile --dependency-output multi_tensor_adam.cuda.o.d -ccbin gcc -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1016\" -I/people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/deepspeed/ops/csrc/adam -isystem /people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/torch/include -isystem /people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/torch/include/TH -isystem /people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/torch/include/THC -isystem /share/apps/cuda/12.3/include -isystem /people/hoan163/.conda/envs/BatchTest/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_90,code=sm_90 -gencode=arch=compute_90,code=compute_90 -DBF16_AVAILABLE -U__CUDA_NO_BFLOAT16_OPERATORS__ -U__CUDA_NO_BFLOAT162_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ -std=c++17 -c /people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o 
[3/3] g++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/people/hoan163/.conda/envs/BatchTest/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/share/apps/cuda/12.3/lib64 -lcudart -o fused_adam.so
Time to load fused_adam op: 90.28594636917114 seconds
[2025-04-04 01:14:58,339] [WARNING] [lr_schedules.py:855:get_lr] Attempting to get learning rate from scheduler before it has started


no_shuffle group_by_length batching 


Loading tokenizer and model

[2025-04-04 01:15:19,687] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /people/hoan163/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
LengthGroupedSampler with Smart Batching: True
ninja: no work to do.
Time to load fused_adam op: 1.3919315338134766 seconds
[2025-04-04 01:15:25,003] [WARNING] [lr_schedules.py:855:get_lr] Attempting to get learning rate from scheduler before it has started
